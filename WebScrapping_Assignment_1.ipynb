{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "977f8490-27d5-4dd8-a734-ca46f5b4d0b6",
   "metadata": {},
   "source": [
    "Q1. What is Web Scraping? Why is it Used? Give three areas where Web Scraping is used to get data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac33cf6e-c362-4f1c-b63e-3b4731261c16",
   "metadata": {},
   "source": [
    "Web scraping is a technique used to collect content and data from the internet. This data is usually saved in a local file so that it can be manipulated and analyzed as needed.\n",
    "\n",
    "Using web scraping we can get different types of data. We can store that in database or in excel. After that we can use that data to analyze something or predict something.\n",
    "\n",
    "Three areas where Web Scraping is used to get data -\n",
    "\n",
    "a. Google uses web scraping to analyze, rank and index their content. Web scraping also allows them to extract information from third-party websites before redirecting it to their own.\n",
    "\n",
    "b. Many companies also carry out contact scraping, which is when they scrape the web for contact information to be used for marketing purposes.\n",
    "\n",
    "c. Market research companies use scrapers to pull data from social media or online forums for things like customer sentiment analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "842277ae-b213-4f8b-ac7d-2cd768381931",
   "metadata": {},
   "source": [
    "Q2. What are the different methods used for Web Scraping?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4477443a-2f13-4f5f-b1d1-b2837240bb42",
   "metadata": {},
   "source": [
    "The different methods used for Web Scraping are - \n",
    "\n",
    "a. Manual Scraping.\n",
    "b. Automated Scraping.\n",
    "c. Outsourced Web Scraping."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e2e8b5a-a51d-47f3-8255-78892d240bf4",
   "metadata": {},
   "source": [
    "Q3. What is Beautiful Soup? Why is it used?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55182090-3655-4c83-a0ba-9b3f399d1e3f",
   "metadata": {},
   "source": [
    "Beautiful Soup is a Python library for getting data out of HTML, XML, and other markup languages.\n",
    "\n",
    "We found some webpages that display data relevant to your research, such as date or address information, but that do not provide any way of downloading the data directly. Beautiful Soup helps you pull particular content from a webpage, remove the HTML markup, and save the information. It is a tool for web scraping that helps us clean up and parse the documents what we have pulled down from the web."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "639d90cf-ddce-4fa4-a58f-3e845ff7e1b6",
   "metadata": {},
   "source": [
    "Q4. Why is flask used in this Web Scraping project?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36acbcca-c430-4904-a907-3b38d230539e",
   "metadata": {},
   "source": [
    "Flask is a lightweight framework to build websites. Weâ€™ll use this to parse our collected data and display it as HTML in a new HTML file.\n",
    "The requests module allows us to send http requests to the website we want to scrape."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e07b009c-b8db-4eba-ae11-e1be6d0142b3",
   "metadata": {},
   "source": [
    "Q5. Write the names of AWS services used in this project. Also, explain the use of each service."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77777511-7ec7-4c57-bbe3-7e442320ee55",
   "metadata": {},
   "source": [
    "AWS Code Pipeline and AWS Elastic Beanstack are used in this project."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b43964f-4716-43c2-a861-36b840c282b4",
   "metadata": {},
   "source": [
    "AWS CodePipeline is a fully managed continuous delivery service that helps you automate your release pipelines for fast and reliable application and infrastructure updates.\n",
    "\n",
    "AWS Elastic Beanstalk is an AWS managed service for web applications. Elastic beanstalk is a pre-configured EC2 server that can directly take up your application code and environment configurations and use it to automatically provision and deploy the required resources within AWS to run the web application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c4647a0-0e49-4cbb-acca-fed0b656d975",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
